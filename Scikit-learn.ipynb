{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ea709e",
   "metadata": {},
   "source": [
    "# Scikit-Learn Doc and Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d649280",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15967cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811204d",
   "metadata": {},
   "source": [
    "## 1. Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1e3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = pd.read_csv('heart-disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d89f4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X which is the feature Matrix & Y which is the label\n",
    "\n",
    "X = hd.drop('target', axis=1)\n",
    "y = hd['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7be123",
   "metadata": {},
   "source": [
    "## 2. Choose the right estimator/algorithm for our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e043c715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# We'll keep the default Hyperparameters\n",
    "\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c1434",
   "metadata": {},
   "source": [
    "## 3. Fit model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eea5ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf906793",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48668b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction\n",
    "y_preds = clf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451340c2",
   "metadata": {},
   "source": [
    "## 4. Evaluate our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cebc322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213114754098361"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a48fd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70        25\n",
      "           1       0.83      0.67      0.74        36\n",
      "\n",
      "    accuracy                           0.72        61\n",
      "   macro avg       0.73      0.73      0.72        61\n",
      "weighted avg       0.74      0.72      0.72        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "467f1fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  5],\n",
       "       [12, 24]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e8e0de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213114754098361"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a56497",
   "metadata": {},
   "source": [
    "## 5. Improve our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db69080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators\n",
      "Model accuracy on test set: 70.49%\n",
      "Trying model with 20 estimators\n",
      "Model accuracy on test set: 77.05%\n",
      "Trying model with 30 estimators\n",
      "Model accuracy on test set: 73.77%\n",
      "Trying model with 40 estimators\n",
      "Model accuracy on test set: 73.77%\n",
      "Trying model with 50 estimators\n",
      "Model accuracy on test set: 73.77%\n",
      "Trying model with 60 estimators\n",
      "Model accuracy on test set: 72.13%\n",
      "Trying model with 70 estimators\n",
      "Model accuracy on test set: 70.49%\n",
      "Trying model with 80 estimators\n",
      "Model accuracy on test set: 77.05%\n",
      "Trying model with 90 estimators\n",
      "Model accuracy on test set: 72.13%\n"
     ]
    }
   ],
   "source": [
    "# Try different amounts of n_estimators (which is another word for hyperparams)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(10,100,10):\n",
    "    print(f\"Trying model with {i} estimators\")\n",
    "    clf = RandomForestClassifier(n_estimators=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(X_test, y_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ade03",
   "metadata": {},
   "source": [
    "## 6. Save the model and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b09427e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open('randomforest_model1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2091a966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213114754098361"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model \n",
    "\n",
    "loaded_model = pickle.load(open('randomforest_model1.pkl','rb'))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f3feb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv('car-sales-extended.csv')\n",
    "\n",
    "X = car_sales.drop('Price', axis=1)\n",
    "y = car_sales['Price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1892b5dd",
   "metadata": {},
   "source": [
    "## Transform the categorical data into numeric data for using in machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9deddd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = ['Make', 'Colour', 'Doors']\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([('one_hot',\n",
    "                                 one_hot,\n",
    "                                 categorical_features)],\n",
    "                               remainder='passthrough')\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a36f5b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3235867221569877"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = RandomForestRegressor()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b071f",
   "metadata": {},
   "source": [
    "## Handling missing data\n",
    "\n",
    "* Fill them with some value (aka imputation)\n",
    "* Remove the samples with missing data altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c643518d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing = pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c452d",
   "metadata": {},
   "source": [
    "--------------------\n",
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02306d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop('Price', axis = 1)\n",
    "y = car_sales_missing['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a5bf78",
   "metadata": {},
   "source": [
    "### Option1: Fill missing data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d741c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This step is NOT required in the new version of Scikit-learn as\n",
    "Scikit-learn handles missing data itself \"\"\"\n",
    "\n",
    "## Fill the 'Make' column\n",
    "\n",
    "car_sales_missing['Make'].fillna('missing', inplace=True)\n",
    "\n",
    "## Fill the 'Colour' column\n",
    "\n",
    "car_sales_missing['Colour'].fillna('missing', inplace=True)\n",
    "\n",
    "## Fill the 'Odometer KM' column\n",
    "\n",
    "car_sales_missing['Odometer (KM)'].fillna(car_sales_missing['Odometer (KM)'].mean(), inplace=True)\n",
    "\n",
    "## Fill the 'Doors' column\n",
    "\n",
    "car_sales_missing['Doors'].fillna(4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "984b75b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb529bdb",
   "metadata": {},
   "source": [
    "## Remove rows with missing price values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb7b3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "589947fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "970cdb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        3.54310e+04, 1.53230e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        1.92714e+05, 1.99430e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        8.47140e+04, 2.83430e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 0.00000e+00,\n",
       "        6.66040e+04, 3.15700e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.15883e+05, 4.00100e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.48360e+05, 1.27320e+04]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to numbers\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "categorical_features = ['Make', 'Colour', 'Doors']\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([('one_hot',\n",
    "                                 one_hot,\n",
    "                                 categorical_features)],\n",
    "                               remainder='passthrough')\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13fb22a",
   "metadata": {},
   "source": [
    "## Option2: Fill missing values with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ccdf0",
   "metadata": {},
   "source": [
    "### Extension: Feature Scaling\n",
    "Once your data is all in numerical format, there's one more transformation you'll probably want to do to it.\n",
    "\n",
    "It's called Feature Scaling.\n",
    "\n",
    "In other words, making sure all of your numerical data is on the same scale.\n",
    "\n",
    "For example, say you were trying to predict the sale price of cars and the number of kilometres on their odometers varies from 6,000 to 345,000 but the median previous repair cost varies from 100 to 1,700. A machine learning algorithm may have trouble finding patterns in these wide-ranging variables.\n",
    "\n",
    "To fix this, there are two main types of feature scaling.\n",
    "\n",
    "Normalization (also called min-max scaling) - This rescales all the numerical values to between 0 and 1, with the lowest value being close to 0 and the highest previous value being close to 1. Scikit-Learn provides functionality for this in the MinMaxScalar class. SRC: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "Standardization - This subtracts the mean value from all of the features (so the resulting features have 0 mean). It then scales the features to unit variance (by dividing the feature by the standard deviation). Scikit-Learn provides functionality for this in the StandardScalar class. SRC: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "**A couple of things to note.**\n",
    "\n",
    "Feature scaling usually isn't required for your target variable.\n",
    "\n",
    "Feature scaling is usually not required with tree-based models (e.g. Random Forest) since they can handle varying features.\n",
    "\n",
    "#### Extra reading\n",
    "\n",
    "For further information on this topic, I'd suggest the following resources. \n",
    "\n",
    "* Feature Scaling - why is it required? by Rahul Saini https://medium.com/@rahul77349/feature-scaling-why-it-is-required-8a93df1af310\n",
    "\n",
    "* Feature Scaling with Scikit-Learn by Ben Alex Keen https://benalexkeen.com/feature-scaling-with-scikit-learn/\n",
    "\n",
    "* Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization by Aniruddha Bhandari https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
    "\n",
    "#### Challenge\n",
    "\n",
    "After reading up on feature scaling, a good idea would be to practice it on one of the problems you're working on and see how it affects the results. If you find anything interesting, be sure to share it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab968b89",
   "metadata": {},
   "source": [
    "### Some notes to take when preparing data\n",
    "\n",
    "* Split your data first (into train/test), always keep your training & test data separate\n",
    "\n",
    "* Fill/transform the training set and test sets separately (this goes for filling data with pandas as well)\n",
    "\n",
    "* Don't use data from the future (test set) to fill data from the past (training set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87d60658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_missing_val = pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "car_missing_val.head()\n",
    "car_missing_val.dropna(subset=['Price'],inplace=True)\n",
    "\n",
    "car_missing_val.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bfb146cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_missing_val.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c6f714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_missing_val.dropna(subset=['Price'],inplace=True)\n",
    "car_missing_val.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aa8283bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>18933.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>146233.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Blue</td>\n",
       "      <td>23545.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124844.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Red</td>\n",
       "      <td>108681.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>51155.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>146703.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>125819.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>10954.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors\n",
       "416   Honda  White        18933.0    4.0\n",
       "100   Honda   Blue       146233.0    4.0\n",
       "371     NaN   Blue        23545.0    4.0\n",
       "20   Toyota    NaN       124844.0    4.0\n",
       "995  Toyota  Black        35820.0    4.0\n",
       "..      ...    ...            ...    ...\n",
       "306   Honda    Red       108681.0    4.0\n",
       "175  Toyota   Blue        51155.0    4.0\n",
       "449   Honda  White       146703.0    4.0\n",
       "25    Honda   Blue       125819.0    4.0\n",
       "403  Nissan   Blue        10954.0    4.0\n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = car_missing_val.drop('Price', axis=1)\n",
    "y = car_missing_val['Price']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "271143a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>146233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>missing</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>missing</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Red</td>\n",
       "      <td>4.0</td>\n",
       "      <td>108681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>146703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10954.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1    2         3\n",
       "0      Honda    White  4.0   18933.0\n",
       "1      Honda     Blue  4.0  146233.0\n",
       "2    missing     Blue  4.0   23545.0\n",
       "3     Toyota  missing  4.0  124844.0\n",
       "4     Toyota    Black  4.0   35820.0\n",
       "..       ...      ...  ...       ...\n",
       "755    Honda      Red  4.0  108681.0\n",
       "756   Toyota     Blue  4.0   51155.0\n",
       "757    Honda    White  4.0  146703.0\n",
       "758    Honda     Blue  4.0  125819.0\n",
       "759   Nissan     Blue  4.0   10954.0\n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fill missing values in scikit-learn\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with missing and numerical values with mean.\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value = 'missing')\n",
    "door_imputer = SimpleImputer(strategy='constant', fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "## Define columns\n",
    "\n",
    "cat_features= ['Make', 'Colour']\n",
    "door_feature= ['Doors']\n",
    "num_features= ['Odometer (KM)']\n",
    "\n",
    "## Create an imputer, something that fills missing data\n",
    "\n",
    "imputer = ColumnTransformer([('cat_imputer', cat_imputer, cat_features),\n",
    "                            ('door_imputer', door_imputer, door_feature),\n",
    "                            ('num_imputer', num_imputer, num_features)])\n",
    "\n",
    "filled_X_train = imputer.fit_transform(X_train)\n",
    "filled_X_test = imputer.fit_transform(X_test)\n",
    "\n",
    "df = pd.DataFrame(filled_X_train)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "60754b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to numbers\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "categorical_features = [0,1,2]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([('one_hot',\n",
    "                                 one_hot,\n",
    "                                 categorical_features)],\n",
    "                               remainder='passthrough')\n",
    "\n",
    "# X_train = pd.DataFrame(filled_X_train,columns=['Make', 'Colour', 'Doors', 'Odometer (KM)'])\n",
    "# X_test = pd.DataFrame(filled_X_test,columns=['Make', 'Colour', 'Doors', 'Odometer (KM)'])\n",
    "\n",
    "\n",
    "transformed_X_train = transformer.fit_transform(filled_X_train)\n",
    "transformed_X_test = transformer.fit_transform(filled_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4ae10d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<760x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3040 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0f6bacb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17680708165422154"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now lets fit the model to our data\n",
    "\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(transformed_X_train, y_train)\n",
    "model.score(transformed_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4867d",
   "metadata": {},
   "source": [
    "## Choosing the right estimator (model) for your problem\n",
    "\n",
    "Some things to note:\n",
    "    \n",
    "    * Sklearn refers to machine learning models, or algorithms as estimators\n",
    "    * Classification problem - predicting a category (heart disease or not)\n",
    "        * sometimes you'll see 'clf' used for classification estimator\n",
    "    * Regression problem - predicting a number (selling price of a car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab0251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 'California housing' Dataset from sklearn\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "housing_df = pd.DataFrame(housing['data'], columns=housing['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a96c189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eea9b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['target'] = housing['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9394addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.drop(['MedHouseVal'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77b6e85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758549611440126"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# separate features and target\n",
    "X = housing_df.drop(['target'], axis=1)\n",
    "y = housing_df['target']\n",
    "\n",
    "\n",
    "# split data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# instantiate and fit the model\n",
    "\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "model.fit(X_train, y_train) \n",
    "model.score(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "906790fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8051230593157366"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fdc4cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Classification Task\n",
    "\n",
    "heart_disease = pd.read_csv('heart-disease.csv')\n",
    "heart_disease.head()\n",
    "\n",
    "np.random.seed(42)\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# model = LinearSVC(max_iter=1000)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f745fd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57797e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11],\n",
       "       [0.49, 0.51],\n",
       "       [0.43, 0.57],\n",
       "       [0.84, 0.16],\n",
       "       [0.18, 0.82],\n",
       "       [0.14, 0.86]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "model.predict_proba(X_test[:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f5f056c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc227741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "X = housing_df.drop('target', axis=1)\n",
    "y = housing_df['target']\n",
    "\n",
    "## split into train-test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "\n",
    "## create the model instance\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_preds = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95059d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49384  , 0.75494  , 4.9285964, 2.54029  , 2.33176  , 1.6549701,\n",
       "       2.34323  , 1.66182  , 2.47489  , 4.8344779])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dcb8e168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.477  , 0.458  , 5.00001, 2.186  , 2.78   , 1.587  , 1.982  ,\n",
       "        1.575  , 3.4    , 4.466  ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([y_test[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c9e6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83160a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066196804802649"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "## Create the data\n",
    "\n",
    "housing_df['target'] = housing['target']\n",
    "X = housing_df.drop(['target'], axis=1)\n",
    "y = housing_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test,y_test)\n",
    "# y_preds = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b711408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49384  , 0.75494  , 4.9285964, 2.54029  , 2.33176  , 1.6549701,\n",
       "       2.34323  , 1.66182  , 2.47489  , 4.8344779])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "035ff9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3265721842781009"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compare predictions to the truth\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test,y_preds)\n",
    "\n",
    "#this means that on average, each one of our test data predictions (y_preds) is ~0.32 different than the true value (y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350264d",
   "metadata": {},
   "source": [
    "## 4. Evaluating a Machine learning model\n",
    "\n",
    "Three ways to evaluate scikit-learn models/estimtors:\n",
    "   1. Estimator's built-in `score()` method\n",
    "   2. The `scoring` parameter\n",
    "   3. Problem-specific metric functions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d21eec",
   "metadata": {},
   "source": [
    "### 4.1 Evaluating a model using `score()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e95a4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "## Create X and y\n",
    "\n",
    "heart_disease = pd.read_csv('heart-disease.csv')\n",
    "X = heart_disease.drop(['target'], axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "## Create train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "## Create classifier model instance\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "## Fit classifier to training data\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2066f679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.86885246, 0.81967213, 0.78333333, 0.76666667])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using Cross-validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e418363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
